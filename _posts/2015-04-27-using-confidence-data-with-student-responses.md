---
id: 3818
title: Using Confidence Data with Student Responses
date: 2015-04-27T16:01:45+00:00
author: Brian Bennett
layout: post
guid: http://blog.ohheybrian.com/?p=3818
permalink: /2015/04/using-confidence-data-with-student-responses/
categories:
  - All
  - Teaching
---
I tried something new today with my students &#8211; I asked them to rate their confidence in their answers on a 1 (total guess) to 4 (definitely know I know it) scale. I collected the aggregate information for each class and started flagging issues.

First, this only took me about 5 minutes to do. So, after we finished the questions, they started working on their review for our test this week. I pulled in the numbers, ran a formula or two, and had the percent correct for each item as well as the average confidence. Then, we started talking about what they noticed.

Some noticed right away that a few questions were more missed than others. Someone also noticed that questions with a high percent correct tended to have a high confidence rating. The same was true for lower-scoring questions. I then pointed out what I was _really_ interested in:

Discrepancy.

I saw nods and furrowed brows as I pointed out low-scoring questions with high confidence ratings. It doesn&#8217;t compute. If so many people got it wrong, why were we so sure it was right?

This highlights areas I need to go back and review again, which is really nice. It also helps students reach a metacognitive place on their own work &#8211; it was only 6 questions, so they know what they got right and wrong.

<img class="aligncenter size-full wp-image-3820" src="http://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-53-50.png" alt="2015-04-27_14-53-50" width="581" height="385" srcset="https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-53-50.png 581w, https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-53-50-300x199.png 300w" sizes="(max-width: 581px) 100vw, 581px" />

<img class="aligncenter size-full wp-image-3821" src="http://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-56-01.png" alt="2015-04-27_14-56-01" width="581" height="383" srcset="https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-56-01.png 581w, https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_14-56-01-300x198.png 300w" sizes="(max-width: 581px) 100vw, 581px" />

<p style="text-align: center;">
  Different classes, different priorities.
</p>

And then here&#8217;s the aggregate data for all classes:

<img src="http://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-08-56.png" alt="2015-04-27_15-08-56" width="637" height="389" class="aligncenter size-full wp-image-3824" srcset="https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-08-56.png 637w, https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-08-56-300x183.png 300w" sizes="(max-width: 637px) 100vw, 637px" />

For now, I&#8217;m adding the red flags myself based on an arbitrary percentage and confidence level discrepancy. I&#8217;m doing that because I don&#8217;t know of any other way to make that comparison. So, here&#8217;s the question:

Are there statistical analyses that can be done on two-variable data (correct vs. confidence) which can then highlight areas significantly lower than expected?

I even went so far as to perform a correlation test on the data, which shows a definite positive correlation between the score and student confidence:

<img src="http://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-59-27.png" alt="2015-04-27_15-59-27" width="667" height="228" class="aligncenter size-full wp-image-3828" srcset="https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-59-27.png 667w, https://blog.ohheybrian.com/wp-content/uploads/2015/04/2015-04-27_15-59-27-300x103.png 300w" sizes="(max-width: 667px) 100vw, 667px" />

But again, I don&#8217;t know how to set up that discrepancy benchmark statistically. I _may_ be thinking too hard about this, but I&#8217;d really like to have more to go on than, &#8220;This one is low compared to confidence.&#8221; It&#8217;s also a _very_ small sample, and I know most correlation tests (t-Test, ANOVA, etc) require 10 samples, usually, so I&#8217;m not putting a ton of weight on the stats.

If you have any experience in this kind of analysis, I&#8217;d appreciate some pointers in the comments.